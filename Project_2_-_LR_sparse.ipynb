{"cells":[{"cell_type":"code","execution_count":1,"id":"fcf998b9","metadata":{"executionInfo":{"elapsed":1197,"status":"ok","timestamp":1679636039198,"user":{"displayName":"Abril Vento Bustamante","userId":"05962190248310156122"},"user_tz":300},"id":"fcf998b9"},"outputs":[],"source":["import numpy as np\n","import scipy.sparse as sparse\n","\n","import tqdm as tqdm\n","from sklearn.model_selection import train_test_split\n","from sklearn.preprocessing import OneHotEncoder, Normalizer\n","\n","seed = 69420\n","np.random.seed(69420)"]},{"cell_type":"code","execution_count":2,"id":"69c5ba78","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":321},"executionInfo":{"elapsed":11506,"status":"error","timestamp":1679636059371,"user":{"displayName":"Abril Vento Bustamante","userId":"05962190248310156122"},"user_tz":300},"id":"69c5ba78","outputId":"948637ad-cdb9-4a16-cb9d-9a3c7f7187f2"},"outputs":[],"source":["def read_sparse_dataset(dataset_name: str, *args, **kwargs) -> sparse.csr_matrix:\n","    with open(dataset_name, 'r') as f:\n","        num_lines = sum(1 for _ in f)\n","\n","    sparse_row_list = []\n","    with open(dataset_name, 'r') as f:\n","        for row in tqdm.tqdm(f, total=num_lines):\n","            data = np.fromstring(row, *args, **kwargs)\n","            sparse_row = sparse.csr_matrix(data)\n","            sparse_row_list.append(sparse_row)\n","\n","    data_matrix: sparse.csr_matrix\n","    data_matrix = sparse.vstack(sparse_row_list) # type: ignore\n","    return data_matrix"]},{"cell_type":"code","execution_count":4,"id":"7f57aa7d","metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["100%|██████████| 12000/12000 [02:38<00:00, 75.91it/s] \n"]}],"source":["Xy_raw: sparse.csr_matrix\n","Xy_raw = read_sparse_dataset('training.csv', sep=',', dtype=np.int32)"]},{"cell_type":"code","execution_count":5,"id":"c99c2419","metadata":{},"outputs":[],"source":["X_raw: sparse.csr_matrix; y_raw: np.ndarray\n","X_raw = Xy_raw[:, 1:-1] # type: ignore\n","y_raw = Xy_raw[:, -1].toarray() # type: ignore"]},{"cell_type":"code","execution_count":5,"id":"73971505","metadata":{},"outputs":[],"source":["scaler = Normalizer()\n","encoder = OneHotEncoder()\n","\n","X_norm: sparse.csr_matrix; y_cat: np.ndarray\n","X_norm = scaler.fit_transform(X_raw)\n","y_cat = encoder.fit_transform(y_raw)"]},{"cell_type":"code","execution_count":6,"id":"a7f1c9b4","metadata":{},"outputs":[],"source":["X_train: sparse.csr_matrix; X_test: sparse.csr_matrix; y_train: np.ndarray; y_test: np.ndarray\n","X_train, X_test, y_train, y_test = train_test_split(X_norm, y_cat, test_size=0.2, random_state=seed) # type: ignore\n","y_train, y_test = y_train.toarray(), y_test.toarray() # type: ignore"]},{"cell_type":"code","execution_count":7,"id":"a21244bb","metadata":{},"outputs":[],"source":["def calculate_loss(*, y, s):\n","    return np.sum(y * np.log(s)) / -y.shape[0]"]},{"cell_type":"code","execution_count":8,"id":"d127cf81","metadata":{},"outputs":[],"source":["def multilogistic(*, z):\n","    return np.exp(z) / np.sum(np.exp(z), axis=1, keepdims=True)"]},{"cell_type":"code","execution_count":9,"id":"9aa842e7","metadata":{},"outputs":[],"source":["def calculate_gradient(*, X, y, s):\n","    return X.T @ (s - y) / y.shape[0]"]},{"cell_type":"code","execution_count":10,"id":"30ce4bc0","metadata":{},"outputs":[],"source":["def predict(*, X, W):\n","    w, b = W[1:], W[0]\n","    return multilogistic(z=X @ w + b)"]},{"cell_type":"code","execution_count":11,"id":"72f27eff","metadata":{},"outputs":[],"source":["def accuracy(*, y_true, y_pred):\n","    return np.sum(y_true == y_pred) / y_true.shape[0]"]},{"cell_type":"code","execution_count":12,"id":"6b7f6827","metadata":{},"outputs":[],"source":["def logistic_regression(X, y, epochs, alpha, lambda_, threshold, W_init=None):\n","    if W_init is None:\n","        W = np.random.normal(0, 0.1, (X.shape[1], y.shape[1])) \n","        W = np.vstack((np.zeros((1, y.shape[1])), W))\n","    else:\n","        W = W_init\n","\n","    X = sparse.hstack((((X.shape[0], 1)), X))\n","    losses = []\n","    i = 0\n","    try:\n","        with tqdm.trange(epochs) as t:\n","            for i in t:\n","                s = multilogistic(z=X @ W)                \n","                gradient = calculate_gradient(X = X, y = y, s = s) + lambda_ * W\n","                \n","                loss = calculate_loss(y = y, s = s) + lambda_ * np.sum(W**2)\n","                losses.append(loss)\n","\n","                accuracy_ = accuracy(y_true = np.argmax(y, axis=1), y_pred = np.argmax(s, axis=1))\n","                t.set_postfix(loss=f\"{loss:.6f}\", accuracy=f\"{accuracy_:.6f}\")\n","\n","                if i > 0 and np.abs(losses[-1] - losses[-2]) < threshold:\n","                    print(\"Converged at epoch \", i)\n","                    break\n","\n","                W = W - alpha * gradient\n","    except KeyboardInterrupt:\n","        print(\"Interrupted by user at epoch \", i)\n","\n","    return W, losses"]},{"cell_type":"code","execution_count":13,"id":"bb33b212","metadata":{},"outputs":[],"source":["W = None"]},{"cell_type":"code","execution_count":21,"id":"b28aa909","metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["  9%|▉         | 940/10000 [02:06<20:18,  7.43it/s, accuracy=0.721146, loss=2.061988]"]},{"name":"stdout","output_type":"stream","text":["Interrupted by user at epoch  940\n"]},{"name":"stderr","output_type":"stream","text":["\n"]}],"source":["W, losses = logistic_regression(X_train, y_train, epochs = 10000, alpha = 1, lambda_ = 1e-4, threshold = 1e-6, W_init = W)"]},{"cell_type":"code","execution_count":22,"id":"ad672748","metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Train accuracy:  0.72125\n"]}],"source":["s = predict(X = X_train, W = W)\n","print(\"Train accuracy: \", accuracy(y_true = np.argmax(y_train, axis=1), y_pred = np.argmax(s, axis=1)))"]},{"cell_type":"code","execution_count":23,"id":"ddae84c3","metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Test accuracy:  0.6558333333333334\n"]}],"source":["s = predict(X = X_test, W = W)\n","print(\"Test accuracy: \", accuracy(y_true = np.argmax(y_test, axis=1), y_pred = np.argmax(s, axis=1)))"]},{"cell_type":"code","execution_count":25,"id":"fd1301bd","metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["100%|██████████| 6774/6774 [00:10<00:00, 666.26it/s]\n"]}],"source":["Xy_testfile_raw: sparse.csr_matrix\n","Xy_testfile_raw = read_sparse_dataset('testing.csv', sep=',', dtype=np.int32)"]},{"cell_type":"code","execution_count":30,"id":"f431bc16","metadata":{},"outputs":[],"source":["X_testfile_raw: sparse.csr_matrix; y_testfile_raw: np.ndarray\n","X_testfile_raw = Xy_testfile_raw[:, 1:-1] # type: ignore\n","y_testfile_raw = Xy_testfile_raw[:, -1].toarray() # type: ignore"]},{"cell_type":"code","execution_count":32,"id":"9e6ea951","metadata":{},"outputs":[{"ename":"ValueError","evalue":"X has 61187 features, but Normalizer is expecting 61188 features as input.","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","Cell \u001b[0;32mIn[32], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m X_testfile_norm: sparse\u001b[39m.\u001b[39mcsr_matrix; y_testfile_cat: np\u001b[39m.\u001b[39mndarray\n\u001b[0;32m----> 2\u001b[0m X_testfile_norm \u001b[39m=\u001b[39m scaler\u001b[39m.\u001b[39;49mtransform(X_testfile_raw)\n\u001b[1;32m      3\u001b[0m y_testfile_cat \u001b[39m=\u001b[39m encoder\u001b[39m.\u001b[39mtransform(y_testfile_raw)\n","File \u001b[0;32m~/Desktop/saada/.venv/lib64/python3.10/site-packages/sklearn/utils/_set_output.py:140\u001b[0m, in \u001b[0;36m_wrap_method_output.<locals>.wrapped\u001b[0;34m(self, X, *args, **kwargs)\u001b[0m\n\u001b[1;32m    138\u001b[0m \u001b[39m@wraps\u001b[39m(f)\n\u001b[1;32m    139\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mwrapped\u001b[39m(\u001b[39mself\u001b[39m, X, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m--> 140\u001b[0m     data_to_wrap \u001b[39m=\u001b[39m f(\u001b[39mself\u001b[39;49m, X, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    141\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(data_to_wrap, \u001b[39mtuple\u001b[39m):\n\u001b[1;32m    142\u001b[0m         \u001b[39m# only wrap the first output for cross decomposition\u001b[39;00m\n\u001b[1;32m    143\u001b[0m         \u001b[39mreturn\u001b[39;00m (\n\u001b[1;32m    144\u001b[0m             _wrap_data_with_container(method, data_to_wrap[\u001b[39m0\u001b[39m], X, \u001b[39mself\u001b[39m),\n\u001b[1;32m    145\u001b[0m             \u001b[39m*\u001b[39mdata_to_wrap[\u001b[39m1\u001b[39m:],\n\u001b[1;32m    146\u001b[0m         )\n","File \u001b[0;32m~/Desktop/saada/.venv/lib64/python3.10/site-packages/sklearn/preprocessing/_data.py:1987\u001b[0m, in \u001b[0;36mNormalizer.transform\u001b[0;34m(self, X, copy)\u001b[0m\n\u001b[1;32m   1970\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Scale each non zero row of X to unit norm.\u001b[39;00m\n\u001b[1;32m   1971\u001b[0m \n\u001b[1;32m   1972\u001b[0m \u001b[39mParameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1984\u001b[0m \u001b[39m    Transformed array.\u001b[39;00m\n\u001b[1;32m   1985\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m   1986\u001b[0m copy \u001b[39m=\u001b[39m copy \u001b[39mif\u001b[39;00m copy \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcopy\n\u001b[0;32m-> 1987\u001b[0m X \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_validate_data(X, accept_sparse\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mcsr\u001b[39;49m\u001b[39m\"\u001b[39;49m, reset\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m)\n\u001b[1;32m   1988\u001b[0m \u001b[39mreturn\u001b[39;00m normalize(X, norm\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnorm, axis\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m, copy\u001b[39m=\u001b[39mcopy)\n","File \u001b[0;32m~/Desktop/saada/.venv/lib64/python3.10/site-packages/sklearn/base.py:588\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[0;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[1;32m    585\u001b[0m     out \u001b[39m=\u001b[39m X, y\n\u001b[1;32m    587\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m no_val_X \u001b[39mand\u001b[39;00m check_params\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mensure_2d\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mTrue\u001b[39;00m):\n\u001b[0;32m--> 588\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_check_n_features(X, reset\u001b[39m=\u001b[39;49mreset)\n\u001b[1;32m    590\u001b[0m \u001b[39mreturn\u001b[39;00m out\n","File \u001b[0;32m~/Desktop/saada/.venv/lib64/python3.10/site-packages/sklearn/base.py:389\u001b[0m, in \u001b[0;36mBaseEstimator._check_n_features\u001b[0;34m(self, X, reset)\u001b[0m\n\u001b[1;32m    386\u001b[0m     \u001b[39mreturn\u001b[39;00m\n\u001b[1;32m    388\u001b[0m \u001b[39mif\u001b[39;00m n_features \u001b[39m!=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_features_in_:\n\u001b[0;32m--> 389\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    390\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mX has \u001b[39m\u001b[39m{\u001b[39;00mn_features\u001b[39m}\u001b[39;00m\u001b[39m features, but \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    391\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mis expecting \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_features_in_\u001b[39m}\u001b[39;00m\u001b[39m features as input.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    392\u001b[0m     )\n","\u001b[0;31mValueError\u001b[0m: X has 61187 features, but Normalizer is expecting 61188 features as input."]}],"source":["X_testfile_norm: sparse.csr_matrix; y_testfile_cat: np.ndarray\n","X_testfile_norm = scaler.transform(X_testfile_raw)\n","y_testfile_cat = encoder.transform(y_testfile_raw)"]}],"metadata":{"colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.0"}},"nbformat":4,"nbformat_minor":5}
